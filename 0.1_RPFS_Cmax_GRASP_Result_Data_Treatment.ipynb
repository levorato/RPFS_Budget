{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPFS GRASP (Cmax objective) - Data treatment of result files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List files in the output folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootfolder = os.getcwd()\n",
    "file_list = []\n",
    "for path in Path(os.path.join(rootfolder, 'output2')).rglob('*.csv'):\n",
    "    file_list.append(path.as_posix())\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process all CSV files and append all data to a single dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for path in Path(os.path.join(rootfolder, 'output')).rglob('*.csv'):\n",
    "    cmd = \"sed -e :1 -e 's/\\(\\[[^]]*\\),/\\1;/g' -e t1 < {} > {}\".format(path.as_posix(), '*'+path.as_posix())\n",
    "    print(cmd)\n",
    "    #os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "for filename in file_list:\n",
    "    print('Processing file ', filename)\n",
    "    df_ = pd.read_csv(filename, delimiter=',')\n",
    "    df_all = df_all.append(df_.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove trailing spaces on column names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.rename(columns=lambda x: x.strip())\n",
    "df_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim existing string columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_all_columns(df):\n",
    "    \"\"\"\n",
    "    Trim whitespace from ends of each value across all series in dataframe\n",
    "    \"\"\"\n",
    "    trim_strings = lambda x: x.strip() if isinstance(x, str) else x\n",
    "    return df.applymap(trim_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = trim_all_columns(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicated headers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all = df_all[(df_all['n'] != 'n')]\n",
    "display(df_all['n'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert column types from object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_column_types(df):\n",
    "    for col in df.columns:\n",
    "        if col in ['alpha','n','m','time_spent','exit_code','solution_value','time_spent.1','time_to_best_sol','iterations','num_visited_solutions','num_improvements','vnd_size']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        elif col in ['first_improvement','random_vnd', 'adaptive']:\n",
    "            df[col] = df[col].astype('bool')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_all = convert_column_types(df_all)\n",
    "df_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include a new column with the instance set name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['instance_set'] = df_all['instance_name'].str[7:11]\n",
    "df_all['instance_set']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the `instance_name` column to remove the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['instance_name'] = df_all['instance_name'].apply(lambda st: st[st.rfind(\"/\")+1:])\n",
    "df_all['instance_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the column budget_Gamma into Gamma1 and Gamma2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame with split value columns\n",
    "new = df_all[\"budget_T\"].str.split(\" \", n = 2, expand = True) \n",
    "# making separate first name column from new data frame \n",
    "df_all[\"Gamma1\"]= new[0] \n",
    "# making separate last name column from new data frame \n",
    "df_all[\"Gamma2\"]= new[1] \n",
    "# convert Gamma columns to numeric\n",
    "df_all[\"Gamma1\"] = pd.to_numeric(df_all[\"Gamma1\"], errors='coerce')\n",
    "df_all[\"Gamma2\"] = pd.to_numeric(df_all[\"Gamma2\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round columns containing time (in seconds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['time_spent'] = df_all['time_spent'].round(2)\n",
    "df_all['time_spent.1'] = df_all['time_spent.1'].round(2)\n",
    "df_all['time_to_best_sol'] = df_all['time_to_best_sol'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for execution errors \n",
    "\n",
    "Exit code != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all.copy()\n",
    "display(df[(df['exit_code'] != 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows with execution errors (exit_code != 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[(df['exit_code'] != 0)]['exit_code'].unique())\n",
    "df = df[(df['exit_code'] == 0)]\n",
    "display(df['exit_code'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort data according to instance_set, instance_name, alpha, n, m, Gamma1 and Gamma2 and set index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sorting dataset...')\n",
    "df = df.sort_values(['instance_set', 'n', 'm', 'alpha', 'instance_name', 'Gamma1', 'Gamma2'])\n",
    "display(df.dtypes)\n",
    "df = df.set_index(['instance_set', 'n', 'm', 'alpha', 'instance_name', 'Gamma1', 'Gamma2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing results, for a given value of alpha, n and m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given group of alpha, n, m and budget_Gamma, there should be 10 results.\n",
    "\n",
    "First we will build a dataframe with the instances list and all required budget values.\n",
    "\n",
    "### TODO IMPLEMENT A SIMILAR MISSING RESULTS STRATEGY FOR THE TAIL INSTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "rootfolder = os.getcwd()\n",
    "jobs_folders = glob.glob(os.path.join(rootfolder, 'instances', 'robust', 'ying', 'data', '*/'), recursive=False)\n",
    "for job_path in jobs_folders:\n",
    "    alpha_folders = glob.glob(os.path.join(job_path, '*/'), recursive=False)\n",
    "    n = job_path[job_path.find('data')+5:job_path.rfind(' jobs')].strip()\n",
    "    #print('n: {}'.format(n))\n",
    "    for alpha_path in alpha_folders:\n",
    "        alpha = alpha_path[alpha_path.find('jobs')+5:alpha_path.rfind('%')].strip()\n",
    "        #print('alpha: {}'.format(alpha))\n",
    "        instance_paths = glob.glob(os.path.join(alpha_path, '*'), recursive=False)\n",
    "        for instance_path in instance_paths:\n",
    "            instance_name = instance_path[instance_path.find('%')+2:]\n",
    "            #print(instance_name)\n",
    "            for gamma1 in [20, 40, 60, 80, 100]:\n",
    "                for gamma2 in [20, 40, 60, 80, 100]:\n",
    "                    for instance_set in ['ying']:\n",
    "                        data.append([instance_set, instance_name.strip(), alpha, n, 2, gamma1, gamma2])\n",
    "df_instances = pd.DataFrame(data, columns=['instance_set', 'instance_name', 'alpha', 'n', 'm', 'Gamma1', 'Gamma2'])\n",
    "for col in df_instances:\n",
    "    if col in ['alpha','n','m','Gamma1','Gamma2']:\n",
    "        df_instances[col] = pd.to_numeric(df_instances[col], errors='coerce')\n",
    "display(df_instances.dtypes)\n",
    "df_instances = df_instances.set_index(['instance_set', 'n', 'm', 'alpha', 'instance_name', 'Gamma1', 'Gamma2'])\n",
    "display(df_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets join the instances dataframe with the results one (left join)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ying = df.reset_index()\n",
    "df_ying = df_ying[(df_ying['instance_set'] == 'ying')]\n",
    "df_ying = df_ying.set_index(['instance_set', 'n', 'm', 'alpha', 'instance_name', 'Gamma1', 'Gamma2'])\n",
    "df_ying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA O CÁLCULO DOS RESULTADOS AUSENTES ESTÁ FUNCIONANDO, PORÉM O TESTE DA PARAMETRIZAÇÃO RODOU APENAS 20% DAS INSTÂNCIAS\n",
    "# PARA CADA GRUPO DE n e alpha, ALÉM DE RODAR APENAS PARA VALORES DE BUDGET IGUAIS (e.g. [20 20]).\n",
    "# POR ESSA RAZÃO, DIVERSAS COMBINAÇÕES DE EXECUÇÃO ABAIXO ESTÃO AUSENTES.\n",
    "df_joined_ying = df_instances.join(df_ying, how='left')\n",
    "df_joined_ying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will export to CSV a list with all rows with NaN values (missing experimental results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = df_joined_ying[~df_joined_ying['batch_id'].isnull()]#.reset_index()[['instance_set', 'n', 'm', 'alpha', 'instance_name', 'Gamma1', 'Gamma2']]\n",
    "print('Number of missing results: ', len(missing_df.index))\n",
    "print('Saving file on folder: ' + rootfolder)\n",
    "fname = os.path.join(rootfolder, 'GRASP_Cmax_missing_results.csv')\n",
    "missing_df.to_csv(fname, sep=';')\n",
    "print('Saved: ' + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(['alpha', 'n', 'm', 'budget_T']).agg({'executionId' : ['count']}).reset_index()\n",
    "df_grouped.columns = [ ' '.join(str(i) for i in col) for col in df_grouped.columns]\n",
    "#df_grouped.reset_index(inplace=True)\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df, values='executionId', index=['alpha', 'n'], columns=['Gamma1', 'Gamma2'], aggfunc='count', fill_value=0)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the dataset to CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Saving file on folder: ' + rootfolder)\n",
    "fname = os.path.join(rootfolder, 'GRASP_Cmax_Ying_all_results.csv')\n",
    "df_ying.to_csv(fname, sep=';')\n",
    "print('Saved: ' + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
